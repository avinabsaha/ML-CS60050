{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('PhishingData.arff','r') as f:\n",
    "        data = []\n",
    "        for l in f.readlines():\n",
    "            data.append([int(x) for x in l.strip('\\r\\n').split(',')])\n",
    "    f.close()\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(x_train, x_test, y_train, y_test):\n",
    "    model = OneVsRestClassifier(SVC(random_state=0))\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, x_test, y_train, y_test):\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    model = OneVsRestClassifier(forest)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearsvm(x_train, x_test, y_train, y_test):\n",
    "    model = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(x_train, x_test, y_train, y_test):\n",
    "    model = OneVsRestClassifier(GaussianNB())\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradboost(x_train, x_test, y_train, y_test):\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneighbors(x_train, x_test, y_train, y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "    model = OneVsRestClassifier(neigh)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(x_train, x_test, y_train, y_test):\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=50)\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(x_train, x_test, y_train, y_test):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(x_train, x_test, y_train, y_test):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-1,hidden_layer_sizes=(7, 3))\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))\n",
    "    target_names = ['class -1', 'class 0', 'class 1']\n",
    "    print(classification_report(y_test, model.predict(x_test), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96765249537892795)\n",
      "('Test Accuracy', 0.87084870848708484)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.89      0.90      0.89       132\n",
      "    class 0       0.85      0.68      0.76        25\n",
      "    class 1       0.85      0.88      0.87       114\n",
      "\n",
      "avg / total       0.87      0.87      0.87       271\n",
      "\n",
      "('Training Accuracy', 0.83733826247689469)\n",
      "('Test Accuracy', 0.81918819188191883)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.83      0.92      0.87       132\n",
      "    class 0       0.00      0.00      0.00        25\n",
      "    class 1       0.81      0.89      0.85       114\n",
      "\n",
      "avg / total       0.75      0.82      0.78       271\n",
      "\n",
      "('Training Accuracy', 0.88077634011090578)\n",
      "('Test Accuracy', 0.83763837638376382)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.88      0.91      0.90       132\n",
      "    class 0       0.60      0.12      0.20        25\n",
      "    class 1       0.80      0.91      0.85       114\n",
      "\n",
      "avg / total       0.82      0.84      0.81       271\n",
      "\n",
      "('Training Accuracy', 0.83641404805914976)\n",
      "('Test Accuracy', 0.80442804428044279)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.84      0.89      0.86       132\n",
      "    class 0       0.00      0.00      0.00        25\n",
      "    class 1       0.77      0.89      0.82       114\n",
      "\n",
      "avg / total       0.73      0.80      0.77       271\n",
      "\n",
      "('Training Accuracy', 0.87245841035120153)\n",
      "('Test Accuracy', 0.84501845018450183)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.86      0.94      0.90       132\n",
      "    class 0       0.60      0.12      0.20        25\n",
      "    class 1       0.84      0.89      0.87       114\n",
      "\n",
      "avg / total       0.83      0.85      0.82       271\n",
      "\n",
      "('Training Accuracy', 0.91589648798521262)\n",
      "('Test Accuracy', 0.8487084870848709)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.89      0.89      0.89       132\n",
      "    class 0       0.67      0.48      0.56        25\n",
      "    class 1       0.83      0.88      0.85       114\n",
      "\n",
      "avg / total       0.84      0.85      0.84       271\n",
      "\n",
      "('Training Accuracy', 0.96765249537892795)\n",
      "('Test Accuracy', 0.87822878228782286)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.90      0.89      0.89       132\n",
      "    class 0       0.88      0.84      0.86        25\n",
      "    class 1       0.85      0.88      0.87       114\n",
      "\n",
      "avg / total       0.88      0.88      0.88       271\n",
      "\n",
      "('Training Accuracy', 0.94085027726432535)\n",
      "('Test Accuracy', 0.88191881918819193)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   class -1       0.89      0.90      0.90       132\n",
      "    class 0       0.83      0.76      0.79        25\n",
      "    class 1       0.88      0.89      0.88       114\n",
      "\n",
      "avg / total       0.88      0.88      0.88       271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = load_data()\n",
    "    train_labels = data[:,9]\n",
    "    train_data = data[:,:9]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)\n",
    "#     X_train.reshape(-1,1)\n",
    "#     X_test.reshape(-1,1)\n",
    "#     y_train.reshape(-1,1)\n",
    "#     y_test.reshape(-1,1)\n",
    "    random_forest(X_train, X_test, y_train, y_test)\n",
    "    linearsvm(X_train, X_test, y_train, y_test)\n",
    "    svm(X_train, X_test, y_train, y_test)\n",
    "    naive_bayes(X_train, X_test, y_train, y_test)\n",
    "    gradboost(X_train, X_test, y_train, y_test)\n",
    "    kneighbors(X_train, X_test, y_train, y_test)\n",
    "    #SGD(X_train, X_test, y_train, y_test)\n",
    "    DT(X_train, X_test, y_train, y_test)\n",
    "    MLP(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
