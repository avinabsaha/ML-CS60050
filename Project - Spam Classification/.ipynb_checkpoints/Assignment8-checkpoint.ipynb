{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('PhishingData.arff','r') as f:\n",
    "        data = []\n",
    "        for l in f.readlines():\n",
    "            data.append([int(x) for x in l.strip('\\r\\n').split(',')])\n",
    "    f.close()\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(x_train, x_test, y_train, y_test):\n",
    "    model = OneVsRestClassifier(SVC(random_state=0))\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, x_test, y_train, y_test):\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    model = OneVsRestClassifier(forest)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearsvm(x_train, x_test, y_train, y_test):\n",
    "    model = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(x_train, x_test, y_train, y_test):\n",
    "    model = OneVsRestClassifier(GaussianNB())\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradboost(x_train, x_test, y_train, y_test):\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneighbors(x_train, x_test, y_train, y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "    model = OneVsRestClassifier(neigh)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(x_train, x_test, y_train, y_test):\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=50)\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT(x_train, x_test, y_train, y_test):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(x_train, x_test, y_train, y_test):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-1,hidden_layer_sizes=(7, 3))\n",
    "    model = OneVsRestClassifier(clf)\n",
    "    model.fit(x_train, y_train)\n",
    "    print('Training Accuracy', model.score(x_train, y_train))\n",
    "    print('Test Accuracy', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Accuracy', 0.96765249537892795)\n",
      "('Test Accuracy', 0.87453874538745391)\n",
      "('Training Accuracy', 0.83733826247689469)\n",
      "('Test Accuracy', 0.81918819188191883)\n",
      "('Training Accuracy', 0.88077634011090578)\n",
      "('Test Accuracy', 0.83763837638376382)\n",
      "('Training Accuracy', 0.83641404805914976)\n",
      "('Test Accuracy', 0.80442804428044279)\n",
      "('Training Accuracy', 0.87245841035120153)\n",
      "('Test Accuracy', 0.84501845018450183)\n",
      "('Training Accuracy', 0.91589648798521262)\n",
      "('Test Accuracy', 0.8487084870848709)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-22f4705d43f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mgradboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mDT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4de83f6c62dc>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hinge\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_iter'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = load_data()\n",
    "    train_labels = data[:,9]\n",
    "    train_data = data[:,:9]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)\n",
    "#     X_train.reshape(-1,1)\n",
    "#     X_test.reshape(-1,1)\n",
    "#     y_train.reshape(-1,1)\n",
    "#     y_test.reshape(-1,1)\n",
    "    random_forest(X_train, X_test, y_train, y_test)\n",
    "    linearsvm(X_train, X_test, y_train, y_test)\n",
    "    svm(X_train, X_test, y_train, y_test)\n",
    "    naive_bayes(X_train, X_test, y_train, y_test)\n",
    "    gradboost(X_train, X_test, y_train, y_test)\n",
    "    kneighbors(X_train, X_test, y_train, y_test)\n",
    "    SGD(X_train, X_test, y_train, y_test)\n",
    "    DT(X_train, X_test, y_train, y_test)\n",
    "    MLP(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
